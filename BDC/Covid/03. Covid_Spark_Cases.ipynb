{
    "metadata": {
        "kernelspec": {
            "name": "pysparkkernel",
            "display_name": "PySpark"
        },
        "language_info": {
            "name": "pyspark",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "python",
                "version": 2
            },
            "pygments_lexer": "python2"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "49f3664f-fca3-407f-8011-fbde655e1a72"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "baseurl = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_\"\r\n",
                "from pyspark.sql.types import *\r\n",
                "import pandas as pd"
            ],
            "metadata": {
                "azdata_cell_guid": "05d49e03-8290-4890-9c0b-ab12cc10959e",
                "tags": []
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "def saveFile(filetype):\r\n",
                "    df = pd.read_csv(baseurl + filetype + \"_global.csv\")\r\n",
                "    df = df.drop(columns=['Lat','Long'])\r\n",
                "    df_unpivoted = df.melt(id_vars=['Province/State','Country/Region'], var_name='Date', value_name=filetype)\r\n",
                "    df_unpivoted['Date'] = pd.to_datetime(df_unpivoted['Date'], format=\"%m/%d/%y\")\r\n",
                "    df_schema = StructType([ StructField(\"Province\", StringType(), True),StructField(\"Country\", StringType(), True),StructField(\"Date\", DateType(), True),StructField(filetype, IntegerType(), True)])\r\n",
                "    df_spark = spark.createDataFrame(df_unpivoted,df_schema)\r\n",
                "    df_spark.createOrReplaceTempView(\"tmpView\")\r\n",
                "    df_spark = spark.sql(\"SELECT Province,Country,Date(Date),\" + filetype + \" FROM tmpView\")\r\n",
                "    df_spark.write.format('csv').option('header',True).mode('overwrite').save('/covid/csv/' + filetype)\r\n",
                "    df_spark.write.format('parquet').mode('overwrite').saveAsTable(filetype,path='/covid/parquet/' + filetype)\r\n",
                "    df_spark.sort([\"Date\",filetype], ascending=False).show(5)"
            ],
            "metadata": {
                "azdata_cell_guid": "a8175f60-31bc-49cf-9b8e-6688bf45ad6c",
                "tags": []
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "saveFile(\"recovered\")\r\n",
                "saveFile(\"deaths\")\r\n",
                "saveFile(\"confirmed\")"
            ],
            "metadata": {
                "azdata_cell_guid": "fbfe6a88-eee6-48e6-a4bf-8e6b00da5272",
                "tags": []
            },
            "outputs": [],
            "execution_count": null
        }
    ]
}